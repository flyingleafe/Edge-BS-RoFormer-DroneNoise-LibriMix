audio:
  chunk_size: 16000  # 1 second at 16 kHz (DN-LM dataset)
  sample_rate: 16000  # Paper: 16 kHz audio
  hop_length: 256  # Paper: hop length 256
  n_fft: 510  # Paper: window size 510
  num_channels: 1
  min_mean_abs: 0.000
  stft:
    n_fft: 510  # Paper: window size 510
    win_length: 510
    hop_length: 256  # Paper: hop length 256
    window: hann_periodic  # Paper: periodic Hann window

preprocessing:
  magnitude_compression:
    beta: 0.15  # Paper: beta = 0.15
    alpha: 0.5  # Paper: alpha = 0.5

model:
  name: diffusion_buffer_bbed
  base_channels: 64
  channels: 96  # Paper: 128 -> 96
  down_blocks: 4  # Paper: 6 -> 4
  up_blocks: 4  # Paper: 6 -> 4
  res_blocks: 1  # Paper: 2 -> 1
  time_embedding_conv2d: true  # Paper: Conv2D time embedding adapter
  output_crop_last_frames: true  # Paper: output cropped to last B frames

diffusion_buffer:
  buffer_size: 20  # B (use <= number of STFT frames per chunk)
  t_eps: 0.03
  t_max: 0.8
  buffer_lengths: [5, 10, 20, 30, 60]  # Paper: B sweep values

sde:
  type: bbed
  diffusion:
    c: 0.08  # Paper: BBED c
    k: 2.6  # Paper: BBED k
  reverse_start: 0.8  # Paper: BBED reverse start

training:
  optimizer: adam  # Paper: Adam
  lr: 1.0e-4  # Paper: 1e-4
  batch_size: 32  # Paper: batch size 32
  ema_momentum: 0.999  # Paper: EMA decay 0.999
  num_epochs: 250  # Paper: 250 epochs
  num_steps: 200
  patience: 2
  reduce_factor: 0.95
  q: 0.95
  coarse_loss_clip: true
  gradient_accumulation_steps: 1
  grad_clip: 0
  use_amp: true
  other_fix: false
  instruments:
    - vocals
    - noise
  target_instrument: vocals
  early_stop:
    enabled: true
    patience: 30
    metric: "si-sdr"

inference:
  batch_size: 10
  num_overlap: 4
