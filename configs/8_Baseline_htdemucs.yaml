audio:
  chunk_size: 16000  # Audio chunk size (samples), usually sample_rate * segment_length, e.g., 44100 Hz * 11 sec = 485100
  min_mean_abs: 0.001  # Minimum mean absolute value of audio signal, used to check if audio is valid
  hop_length: 1024  # STFT hop length, affects frequency resolution and computation efficiency

training:
  batch_size: 12  # Training batch size, number of samples per training iteration
  gradient_accumulation_steps: 1  # Gradient accumulation steps, accumulate gradients over multiple mini-batches before update
  grad_clip: 0  # Gradient clipping threshold, 0 means no clipping, used to control gradient explosion
  segment: 1  # Audio segment length (seconds), defines duration of each training sample
  # shift: 1  # Audio segment shift (seconds), used for data augmentation or generating more training samples
  samplerate: 16000  # Audio sample rate (Hz), 44100 Hz is CD quality standard
  channels: 1  # Number of audio channels, 2 for stereo (left and right)
  normalize: true  # Whether to normalize audio, usually to unify input amplitude
  instruments:  # Instruments used in training
    - vocals  # Vocals
    - noise  # Noise
  target_instrument: vocals  # Target instrument
  num_epochs: 1000  # Total number of training epochs
  num_steps: 200  # Total training steps, may be related to num_epochs, used to control training progress
  optimizer: adamw  # Optimizer type, Adam optimizer suitable for most deep learning tasks
  lr: 5.0e-4  # Learning rate
  patience: 2  # Early stopping patience, epochs to continue training after no improvement
  reduce_factor: 0.95  # Learning rate reduction factor, LR multiplied by this when performance plateaus
  q: 0.95  # May be quantile or other threshold, used for loss function or evaluation metrics
  coarse_loss_clip: true  # Whether to clip coarse loss, may be used for training stability
  ema_momentum: 0.999  # Exponential moving average momentum, used for model parameter smoothing
  other_fix: false  # Whether to fix "other" stem processing, for multi-song datasets
  use_amp: true  # Whether to use automatic mixed precision (float16), speeds up training and reduces memory
  early_stop:  # Early stopping configuration
    enabled: true  # Whether to enable early stopping
    patience: 30  # Early stopping patience
    metric: "si-sdr"  # Metric for early stopping

augmentations:
  enable: true  # Whether to enable all data augmentation, can quickly disable to simplify training
  loudness: true  # Whether to randomly adjust loudness of each audio stem
  loudness_min: 0.5  # Minimum loudness variation value
  loudness_max: 1.5  # Maximum loudness variation value
  mixup: true  # Whether to enable mixup augmentation, mix stems of same type for data diversity
  mixup_probs: [0.2, 0.02]  # Mixup probabilities, may correspond to different stems (e.g., vocals and other)
  mixup_loudness_min: 0.5  # Minimum loudness during mixup
  mixup_loudness_max: 1.5  # Maximum loudness during mixup

inference:
  num_overlap: 2  # Number of overlaps during inference, for smoothing output and avoiding boundary effects
  batch_size: 8  # Inference batch size, affects speed and memory usage

model: htdemucs  # Specifies model to use: htdemucs, a hybrid Transformer Demucs model

htdemucs:  # HTDemucs model configuration, implementation in demucs/htdemucs.py
  # Channel settings
  channels: 48  # Initial model channels, affects model capacity and computation complexity
  channels_time:  # Time dimension channels, may be dynamically computed
  growth: 2  # Channel growth factor, controls channel increase per layer
  # STFT parameters
  num_subbands: 1  # Number of subbands, for frequency domain processing
  nfft: 4096  # STFT FFT size, determines frequency resolution
  wiener_iters: 0  # Wiener filtering iterations, 0 means no Wiener post-processing
  end_iters: 0  # End iterations, may be for post-processing, 0 means disabled
  wiener_residual: false  # Whether to keep Wiener filtering residual
  cac: true  # Whether to enable channel attention or similar technique
  # Main structure
  depth: 4  # Model depth (layers), controls model complexity
  rewrite: true  # Whether to rewrite certain layers or parameters for optimization
  # Frequency branch
  multi_freqs: []  # Multi-frequency configuration, empty list means disabled
  multi_freqs_depth: 3  # Multi-frequency processing depth
  freq_emb: 0.2  # Frequency embedding parameter, controls embedding strength
  emb_scale: 10  # Embedding scale factor
  emb_smooth: true  # Whether to smooth embeddings
  # Convolution settings
  kernel_size: 8  # Convolution kernel size, affects receptive field
  stride: 4  # Convolution stride, controls downsampling rate
  time_stride: 2  # Time dimension stride, affects time resolution
  context: 1  # Context size, may be for convolution padding or dilation
  context_enc: 0  # Encoder context size, 0 means no extra context
  # Normalization
  norm_starts: 4  # Layer at which normalization starts, from layer 4
  norm_groups: 4  # Normalization groups, for GroupNorm
  # Depthwise convolution residual branch
  dconv_mode: 3  # Depthwise convolution mode, controls residual branch behavior
  dconv_depth: 2  # Depthwise convolution depth
  dconv_comp: 8  # Depthwise convolution compression rate
  dconv_init: 1e-3  # Depthwise convolution initialization value
  # Parameters before Transformer
  bottom_channels: 512  # Bottom channels, usually deepest layer channel count
  # CrossTransformer settings
  # General parameters
  t_layers: 5  # Transformer layers
  t_hidden_scale: 4.0  # Transformer hidden layer scale factor
  t_heads: 8  # Transformer attention heads
  t_dropout: 0.0  # Transformer dropout rate, 0 means no dropout
  t_layer_scale: True  # Whether to enable layer scaling
  t_gelu: True  # Whether to use GELU activation function
  # Position embedding
  t_emb: sin  # Position embedding type, sin for sinusoidal embedding
  t_max_positions: 10000  # Maximum positions, for scaling embedding
  t_max_period: 10000.0  # Position embedding max period
  t_weight_pos_embed: 1.0  # Position embedding weight
  t_cape_mean_normalize: True  # Whether to mean normalize CAPE embeddings
  t_cape_augment: True  # Whether to augment CAPE embeddings
  t_cape_glob_loc_scale: [5000.0, 1.0, 1.4]  # CAPE global and local scale parameters
  t_sin_random_shift: 0  # Sinusoidal embedding random shift, 0 means none
  # Normalization before Transformer encoder
  t_norm_in: True  # Whether to normalize before Transformer encoder
  t_norm_in_group: False  # Whether to use group normalization
  # Internal encoder normalization
  t_group_norm: False  # Whether to use group normalization inside encoder
  t_norm_first: True  # Whether to normalize first (LayerNorm First)
  t_norm_out: True  # Whether to normalize output
  # Optimization parameters
  t_weight_decay: 0.0  # Weight decay coefficient, 0 means none
  t_lr:  # Learning rate, may be dynamically set
  # Sparsity settings
  t_sparse_self_attn: False  # Whether to use sparse self-attention
  t_sparse_cross_attn: False  # Whether to use sparse cross-attention
  t_mask_type: diag  # Mask type, diag for diagonal mask
  t_mask_random_seed: 42  # Mask random seed for reproducibility
  t_sparse_attn_window: 400  # Sparse attention window size
  t_global_window: 100  # Global window size
  t_sparsity: 0.95  # Sparsity level
  t_auto_sparsity: False  # Whether to auto-adjust sparsity
  # Cross-encoding priority
  t_cross_first: False  # Whether to prioritize cross-encoding
  # Weight initialization
  rescale: 0.1  # Weight rescaling factor
